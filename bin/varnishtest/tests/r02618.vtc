varnishtest "sweep through tight client workspace conditions in deliver"

server s1 {
	rxreq
	txresp -hdr "Cache-Control: mag-age=3600" -bodylen 1024
} -start

varnish v1 -arg "-a ${tmpdir}/v1.sock" -vcl+backend {
	import vtc;
	sub vcl_recv {
		return (hash);
	}
	sub vcl_deliver {
		if (req.method == "GET") {
			vtc.workspace_alloc(client, -2 * (req.xid - 1001));
		} else if (req.method == "HEAD") {
			vtc.workspace_alloc(client, -2 * (req.xid - 1202));
		}
	}
} -start

varnish v1 -cliok "param.set vsl_mask -ReqHeader,-ReqUnset"
varnish v1 -cliok "param.set vsl_mask -ReqProtocol"
varnish v1 -cliok "param.set vsl_mask -RespHeader,-RespUnset"
varnish v1 -cliok "param.set vsl_mask -RespReason,-RespProtocol"
varnish v1 -cliok "param.set vsl_mask -Timestamp,-Debug"
varnish v1 -cliok "param.set vsl_mask -VCL_call,-VCL_return,-Hit"

logexpect l1 -v v1 -g raw {
	expect * *	VCL_Error	"Attempted negative WS allocation"
	expect * *	Error		"Failure to push v1d processor"
	expect * *	VCL_Error	"Attempted negative WS allocation"
	expect * *	Error		"workspace_client overflow"
} -start

# some responses will fail (503), some won't. All we care
# about here is the fact that we don't panic
client c1 -connect "${tmpdir}/v1.sock" -repeat 100 {
	txreq -url "/"
	rxresp
} -run
client c1 -connect "${tmpdir}/v1.sock" -repeat 100 {
	txreq -url "/" -method "HEAD"
	rxresp
} -run

logexpect l1 -wait